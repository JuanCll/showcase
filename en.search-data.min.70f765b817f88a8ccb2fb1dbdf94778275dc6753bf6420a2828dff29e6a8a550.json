[{"id":0,"href":"/showcase/docs/shortcodes/Shaders/Backrooms/","title":"Backrooms","section":"Shaders","content":" Backrooms # Marco teórico\nSe utilizaron dos fragment shaders para incluir dos nuevos modelos de iluminación dentro de los Backrooms.\nsketch3.frag // precision mediump float; // // emitted by p5 color-group commands // // https://p5js.org/reference/#group-Color // uniform vec4 uMaterialColor; // uniform vec4 ambient4; // uniform float ambient; // void main() { // // Ambient Light // // gl_FragColor = (ambient + ambient4) * uMaterialColor; // gl_FragColor = (ambient) * uMaterialColor; // } precision mediump float; uniform float ambient; uniform vec4 uMaterialColor; // uLightPosition is given in eye space uniform vec3 uLightPosition; // both, normal3 and position4 are given in eye space as well varying vec3 normal3; varying vec3 position4; void main() { // solve the diffuse light equation discarding negative values // see: https://thebookofshaders.com/glossary/?search=max // see: https://thebookofshaders.com/glossary/?search=dot float diffuse = dot(uLightPosition, vec3(0.01,0.01,0.01)) / 10.0; gl_FragColor = (ambient + diffuse) * uMaterialColor; } sketch4.frag precision mediump float; // emitted by p5 color-group commands // https://p5js.org/reference/#group-Color uniform vec4 uMaterialColor; uniform vec4 lightColor; uniform float ambient; void main() { vec4 ambient4 = lightColor * ambient; gl_FragColor = ambient * ambient4 * uMaterialColor; } Resultados\nEnlace a los Backrooms: INSIDE THE BACKROOMS\nConclusiones\nA partir de la experimetación realizada en este proyecto, pueden verse algunas aplicaciones de shaders, con el fin de mejorar y terminar el ambiente creado previamente. La interpretación o percepción que puede tenerse sobre cualquier tipo de contenido visual o audiovisual puede ser fácilmente manipulado si se tienen en cuenta aspectos importantes como lo son la iluminación, el movimiento y la dinámica de la composición. "},{"id":1,"href":"/showcase/docs/shortcodes/Shaders/Color_Blend/","title":"Color Blend","section":"Shaders","content":" Ejercicios: Coloring # CMY y RGB # Marco teórico\nRGB es un modelo de color basado en la síntesis aditiva, con el que es posible representar un color mediante la mezcla por adición de los tres colores de luz primarios. El modelo CMY es un modelo de color sustractivo que se utiliza en la impresión en colores. Es la versión moderna y más precisa del antiguo modelo tradicional de coloración (RYB).\nEn el sketch a continuación se ve como se alterna entre estos dos modelos de color. Resultados\nColor Blending # Marco teórico\nEl Color Blending es una manera de mezclar dos colores, produciendo un tercer color. Los colores son llamados fuente y destino, y se presentan en forma [R,G,B,A], donde estos valores se encuentran entre 0 y 1.\nResultados\nblending js let shaderb; let shadera; let uMaterial1; let uMaterial2; let brightness; const opcionesS = {\u0026#39;None\u0026#39;: 0, \u0026#39;blend\u0026#39;:1, \u0026#39;add\u0026#39;:2,\u0026#39;darkest\u0026#39;:3,\u0026#39;lightest\u0026#39;:4, \u0026#39;difference\u0026#39;:5, \u0026#39;burn\u0026#39;:6}; function preload() { shaderb = readShader(\u0026#39;/showcase/sketches/SHADERS/blend/color_blend.frag\u0026#39;, { matrices: Tree.pmvMatrix, varyings: Tree.NONE }); shadera = readShader(\u0026#39;/showcase/sketches/SHADERS/blend/color_add.frag\u0026#39;, { matrices: Tree.pmvMatrix, varyings: Tree.NONE }); shaderd = readShader(\u0026#39;/showcase/sketches/SHADERS/blend/color_darkest.frag\u0026#39;, { matrices: Tree.pmvMatrix, varyings: Tree.NONE }); shaderl = readShader(\u0026#39;/showcase/sketches/SHADERS/blend/color_lightest.frag\u0026#39;, { matrices: Tree.pmvMatrix, varyings: Tree.NONE }); shaderdif = readShader(\u0026#39;/showcase/sketches/SHADERS/blend/color_difference.frag\u0026#39;, { matrices: Tree.pmvMatrix, varyings: Tree.NONE }); shaderburn = readShader(\u0026#39;/showcase/sketches/SHADERS/blend/color_burn.frag\u0026#39;, { matrices: Tree.pmvMatrix, varyings: Tree.NONE }); } function setup() { createCanvas(300, 300, WEBGL); noStroke(); modo = createSelect(); modo.position(215, 270); modo.style(\u0026#39;width\u0026#39;, \u0026#39;90px\u0026#39;); modo.option(\u0026#39;None\u0026#39;); modo.option(\u0026#39;blend\u0026#39;); modo.option(\u0026#39;add\u0026#39;); modo.option(\u0026#39;darkest\u0026#39;); modo.option(\u0026#39;ligthtest\u0026#39;); modo.option(\u0026#39;difference\u0026#39;); modo.option(\u0026#39;burn\u0026#39;); colorPicker1 = createColorPicker(\u0026#39;blue\u0026#39;); colorPicker1.position(0, 0); colorPicker2 = createColorPicker(\u0026#39;yellow\u0026#39;); colorPicker2.position(250, 0); slider = createSlider(0, 1, 0.5, 0.01); slider.position(10, 270); slider.style(\u0026#39;width\u0026#39;, \u0026#39;80px\u0026#39;); } function draw() { translate(-150,-150); push(); uMaterial1 = colorPicker1.color() fill(uMaterial1); beginShape(); vertex(30, 40); vertex(130, 40); vertex(130, 140); vertex(30, 140); endShape(); uMaterial2 = colorPicker2.color() fill(uMaterial2); beginShape(); vertex(270, 40); vertex(170, 40); vertex(170, 140); vertex(270, 140); endShape(); pop(); if(opcionesS[modo.value()] == 1){ push(); shader(shaderb); beginShape(); shaderb.setUniform(\u0026#39;uMaterial1\u0026#39;, uMaterial1.levels); shaderb.setUniform(\u0026#39;uMaterial2\u0026#39;, uMaterial2.levels); shaderb.setUniform(\u0026#39;brightness\u0026#39;, slider.value()); vertex(200, 260); vertex(100, 260); vertex(100, 160); vertex(200, 160); endShape(); pop(); } else if(opcionesS[modo.value()] == 2){ push(); shader(shadera); beginShape(); shadera.setUniform(\u0026#39;uMaterial1\u0026#39;, uMaterial1.levels); shadera.setUniform(\u0026#39;uMaterial2\u0026#39;, uMaterial2.levels); vertex(200, 260); vertex(100, 260); vertex(100, 160); vertex(200, 160); endShape(); pop(); } else if(opcionesS[modo.value()] == 3){ push(); shader(shaderd); beginShape(); shaderd.setUniform(\u0026#39;uMaterial1\u0026#39;, uMaterial1.levels); shaderd.setUniform(\u0026#39;uMaterial2\u0026#39;, uMaterial2.levels); vertex(200, 260); vertex(100, 260); vertex(100, 160); vertex(200, 160); endShape(); pop(); } else if(opcionesS[modo.value()] == 4){ push(); shader(shaderl); beginShape(); shaderl.setUniform(\u0026#39;uMaterial1\u0026#39;, uMaterial1.levels); shaderl.setUniform(\u0026#39;uMaterial2\u0026#39;, uMaterial2.levels); vertex(200, 260); vertex(100, 260); vertex(100, 160); vertex(200, 160); endShape(); pop(); } else if(opcionesS[modo.value()] == 5){ push(); shader(shaderdif); beginShape(); shaderdif.setUniform(\u0026#39;uMaterial1\u0026#39;, uMaterial1.levels); shaderdif.setUniform(\u0026#39;uMaterial2\u0026#39;, uMaterial2.levels); vertex(200, 260); vertex(100, 260); vertex(100, 160); vertex(200, 160); endShape(); pop(); } else if(opcionesS[modo.value()] == 6){ push(); shader(shaderburn); beginShape(); shaderburn.setUniform(\u0026#39;uMaterial1\u0026#39;, uMaterial1.levels); shaderburn.setUniform(\u0026#39;uMaterial2\u0026#39;, uMaterial2.levels); vertex(200, 260); vertex(100, 260); vertex(100, 160); vertex(200, 160); endShape(); pop(); } } blending add frag precision mediump float; uniform vec4 uMaterial1; uniform vec4 uMaterial2; void main() { gl_FragColor = uMaterial1 + uMaterial2; } blending difference frag precision mediump float; uniform vec4 uMaterial1; uniform vec4 uMaterial2; void main() { gl_FragColor = max(uMaterial1, uMaterial2) - min(uMaterial1, uMaterial2); } blending lightest frag precision mediump float; uniform vec4 uMaterial1; uniform vec4 uMaterial2; void main() { gl_FragColor = max(uMaterial1, uMaterial2); } blending darkest frag precision mediump float; uniform vec4 uMaterial1; uniform vec4 uMaterial2; void main() { gl_FragColor = min(uMaterial1, uMaterial2); } blending burn frag precision mediump float; uniform vec4 uMaterial1; uniform vec4 uMaterial2; void main() { gl_FragColor = max((1.0-((1.0-uMaterial1)/uMaterial2)),0.0); } blending frag precision mediump float; uniform float brightness; uniform vec4 uMaterial1; uniform vec4 uMaterial2; void main() { gl_FragColor = brightness * uMaterial1 * uMaterial2; } Conclusiones\nLos colores y su manejo en la computación, representan no solo una amplia cantidad de conceptos de tipo matemático, si no también una amplica gama de posibilidades ante la capacidad de su configuración y mezcla, como se pudo ver en los ejercicios presentados. Referencias # https://www.deepskycolors.com/archive/2010/04/21/formulas-for-Photoshop-blending-modes.html https://p5js.org/reference/#/p5/blendMode https://visualcomputing.github.io/docs/shaders/coloring/ https://cglearn.codelight.eu/pub/computer-graphics/blending "},{"id":2,"href":"/showcase/docs/shortcodes/Shaders/Lighting/","title":"Lighting","section":"Shaders","content":" Lighting # Gracias a la iluminación en la computación grafica se puede llegar a dar más detalle a los materiales, imágenes y figuras recreadas en un programa.\nExisten dos principales modelos de iluminación, Object oriented lighting (iluminación directa) y Global illumination (iluminación indirecta), el primero se define como el usar una iluminación para un solo objeto, mientras en la segunda da luz a toda la escena.\nExercise Colored Ambient light\nImplement a scene having the following lighting equation: $\\mathbf{a} = ambient , ambient4a=ambientambient4$, where ambient4ambient4 is the ambient light color.\nambient.js let shaderAL; let Slider1,Slider2; let ColorPicker1,ColorPicker2; let Figures; let r; function preload() { shaderAL = readShader(\u0026#34;/showcase/sketches/SHADERS/Lighting/AL.frag\u0026#34;, { varyings: Tree.NONE, }); } function setup() { createCanvas(400, 400, WEBGL); noLights(); colorMode(RGB, 1); Figures = []; for (let i = 0; i \u0026lt; 100; i++) { Figures.push({ position: createVector( (random() * 2 - 1) * 85, (random() * 2 - 1) * 85, (random() * 2 - 1) * 85 ), size: random() * 20 + 8, color: color(random(), random(), random()), }); } Slider2 = createSlider(1, Figures.length, int(Figures.length / 2), 1); Slider2.position(10, 35); Slider1 = createSlider(0, 1, 1, 0.05); Slider1.position(10,55); Slider1.input(() =\u0026gt; { shaderAL.setUniform(\u0026#34;ambient\u0026#34;, Slider1.value()); }); ColorPicker1 = createColorPicker(\u0026#34;#FFFFFF\u0026#34;); ColorPicker1.position(350,35); ColorPicker1.input(() =\u0026gt; { shaderAL.setUniform(\u0026#34;lightColor\u0026#34;, [ red(ColorPicker1.color()) / 255, green(ColorPicker1.color()) / 255, blue(ColorPicker1.color()) / 255, 1, ]); }); ColorPicker2 = createColorPicker(\u0026#34;#FFFFFF\u0026#34;); ColorPicker2.position(350,65); shader(shaderAL); shaderAL.setUniform(\u0026#34;ambient\u0026#34;, Slider1.value()); shaderAL.setUniform(\u0026#34;lightColor\u0026#34;, [1, 1, 1, 1]); } function draw() { orbitControl(); background(ColorPicker2.color()); resetShader(); push(); stroke(\u0026#34;BLACK\u0026#34;); axes(); grid(); pop(); shader(shaderAL); for (let i = 0; i \u0026lt; Slider2.value(); i++) { push(); noStroke(); fill(Figures[i].color); translate(Figures[i].position); r = Figures[i].size / 2; i % 3 === 0 ? box(r * 2) : i % 3 === 1 ? sphere(r) : torus(r, r / 4); pop(); } } ambient.frag precision mediump float; // emitted by p5 color-group commands // https://p5js.org/reference/#group-Color uniform vec4 uMaterialColor; uniform vec4 lightColor; uniform float ambient; void main() { vec4 ambient4 = lightColor * ambient; gl_FragColor = ambient * ambient4 * uMaterialColor; } Conclusión\nLa iluminación es un complemento muy poderoso al momento de crear un escenario gráfico y, dependiendo de la forma de su implementación, se pueden generar diferentes efectos, como una luz tenue puede crear un ambiente terrorífico, mientras que una iluminación potente en el mismo escenario podría dar la impresión de una temática diferente. Referencias # https://en.wikipedia.org/wiki/Computer_graphics_lighting#Object_oriented_lighting https://colinbarrebrisebois.com/2015/11/06/finding-next-gen-part-i-the-need-for-robust-and-fast-global-illumination-in-games/ https://visualcomputing.github.io/docs/shaders/lighting/ "},{"id":3,"href":"/showcase/docs/shortcodes/Shaders/Photomosaic/","title":"Photomosaic","section":"Shaders","content":" Ejercicios: Photomosaic # ASCII art # Marco teórico\nUn fotomosaico es una foto compuesta de una colección de imágenes más pequeñas, las cuales son ordenadas de tal manera en que presenten una imagen más grande. El Arte ASCII es un medio artítico donde se utilizan los caracteres que componen al código ASCII para la construcción de imágenes. Este ha sido utilizado cuando no es posible la transmisión de imágenes en dispositivos computarizados que no cuentan con los recursos necesarios, como lo son tarjetas de proceso gráfico. Exercise\nImplement a mosaic (or/and ascii art) visual application.\nphotomosaic.js const density = \u0026#39;ABCDEFGHIJKLMNOPQRSTUV@+-=_. \u0026#39;; let imagen; function preload() { imagen = loadImage(\u0026#34;/showcase/sketches/image.jpg\u0026#34;); } function setup() { createCanvas(400, 400); //ascii = createCheckbox(\u0026#39;ascii\u0026#39;, false); } function draw() { //background(0); let w = width / imagen.width; let h = height / imagen.height; imagen.loadPixels(); //image(imagen, 0, 0, imagen.width * 9, imagen.height * 9); image(imagen,0,0); for (let i = 0; i \u0026lt; imagen.width; i++) { for (let j = 0; j \u0026lt; imagen.height; j++) { const pixelIndex = (i + j * imagen.width) * 4; const r = imagen.pixels[pixelIndex + 0]; const g = imagen.pixels[pixelIndex + 1]; const b = imagen.pixels[pixelIndex + 2]; const avg = (r + g + b) / 3; noStroke(); fill(255); const len = density.length; const charIndex = floor(map(avg,0,255,len,0)); textSize(w); textAlign(CENTER, CENTER); fill(r,g,b); text(density.charAt(charIndex), i * w + w * 0.5, j * h + h * 0.5); } } } Conclusiones\nExisten múltiples maneras de transmitir información en forma de imágenes, a pesar de no contar con los medios visuales usualmente utilizados para este fin. El arte ASCII se puede utilizar para mostrar imágenes añadiéndoles diferentes efectos según la intención, y para ocultar o censurar algunos detalles de la imagen. Referencias # https://visualcomputing.github.io/docs/shaders/texturing/ https://github.com/jamieowen/glsl-blend "},{"id":4,"href":"/showcase/docs/shortcodes/Shaders/Procedural_texturing/","title":"Procedural Texturing","section":"Shaders","content":" Procedural texturing # En computación gráfica, una textura procedimental es una textura creada mediante una descripción matemática (es decir, un algoritmo), en lugar de datos almacenados directamente. La ventaja de este enfoque es el bajo coste de almacenamiento, la resolución ilimitada de las texturas y la facilidad de mapeo de las mismas.\nprocedural texturing js let pg; let colt; let truchetShader; let colorShader; let brickShader; let dotsShader; let textura; const opcionesS = {\u0026#39;None\u0026#39;: 0, \u0026#39;truchet\u0026#39;:1, \u0026#39;color\u0026#39;:2,\u0026#39;bricks\u0026#39;:3,\u0026#39;dots\u0026#39;:4, \u0026#39;plasma\u0026#39;:5}; function preload() { // shader adapted from here: https://thebookofshaders.com/09/ truchetShader = readShader(\u0026#39;/showcase/sketches/SHADERS/texturing/texturing_truchet.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.NONE }); colorShader = readShader(\u0026#39;/showcase/sketches/SHADERS/texturing/texturing_color.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.NONE }); brickShader = readShader(\u0026#39;/showcase/sketches/SHADERS/texturing/texturing_bricks.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.NONE }); dotsShader = readShader(\u0026#39;/showcase/sketches/SHADERS/texturing/texturing_dots.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.NONE }); plasmaShader = readShader(\u0026#39;/showcase/sketches/SHADERS/texturing/texturing_plasma.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.NONE }) } function setup() { createCanvas(400, 400, WEBGL); // create frame buffer object to render the procedural texture pg = createGraphics(400, 400, WEBGL); textureMode(NORMAL); noStroke(); texturaD = \u0026#39;None\u0026#39; textura = createSelect(); textura.position(15, 15); textura.style(\u0026#39;width\u0026#39;, \u0026#39;90px\u0026#39;); textura.option(\u0026#39;None\u0026#39;); textura.option(\u0026#39;truchet\u0026#39;); textura.option(\u0026#39;color\u0026#39;); textura.option(\u0026#39;bricks\u0026#39;); textura.option(\u0026#39;dots\u0026#39;); textura.option(\u0026#39;plasma\u0026#39;); } function draw() { background(33); orbitControl(); cylinder(100, 200); console.log(opcionesS[textura.value()]); if(opcionesS[textura.value()] == 0){ pg.textureMode(NORMAL); pg.noStroke(); pg.quad(-1, -1, 1, -1, 1, 1, -1, 1); texture(pg); } else if(opcionesS[textura.value()] == 1){ pg.textureMode(NORMAL); pg.noStroke(); pg.shader(truchetShader); // emitResolution, see: // https://github.com/VisualComputing/p5.treegl#macros pg.emitResolution(truchetShader); // https://p5js.org/reference/#/p5.Shader/setUniform truchetShader.setUniform(\u0026#39;u_zoom\u0026#39;, 3); // pg clip-space quad (i.e., both x and y vertex coordinates ∈ [-1..1]) pg.quad(-1, -1, 1, -1, 1, 1, -1, 1); // set pg as texture texture(pg); } else if (opcionesS[textura.value()] == 2){ pg.textureMode(NORMAL); pg.noStroke(); pg.shader(colorShader); pg.emitResolution(colorShader); //colorShader.setUniform(\u0026#39;u_zoom\u0026#39;, 3); pg.quad(-1, -1, 1, -1, 1, 1, -1, 1); texture(pg); } else if (opcionesS[textura.value()] == 3){ pg.textureMode(NORMAL); pg.noStroke(); pg.shader(brickShader); pg.emitResolution(brickShader); //brickShader.setUniform(\u0026#39;u_zoom\u0026#39;, 3); pg.quad(-1, -1, 1, -1, 1, 1, -1, 1); texture(pg); } else if (opcionesS[textura.value()] == 4){ pg.textureMode(NORMAL); pg.noStroke(); pg.shader(dotsShader); pg.emitResolution(dotsShader); //dotsShader.setUniform(\u0026#39;u_zoom\u0026#39;, 3); pg.quad(-1, -1, 1, -1, 1, 1, -1, 1); texture(pg); } else if (opcionesS[textura.value()] == 5){ pg.textureMode(NORMAL); pg.noStroke(); pg.shader(plasmaShader); pg.emitResolution(plasmaShader); //dotsShader.setUniform(\u0026#39;u_zoom\u0026#39;, 3); pg.quad(-1, -1, 1, -1, 1, 1, -1, 1); texture(pg); } } function mouseMoved() { // https://p5js.org/reference/#/p5.Shader/setUniform truchetShader.setUniform(\u0026#39;_zoom\u0026#39;, int(map(mouseX, 0, width, 1, 30))); // pg clip-space quad (i.e., both x and y vertex coordinates ∈ [-1..1]) pg.quad(-1, -1, 1, -1, 1, 1, -1, 1); } fragment shader truchet #ifdef GL_ES precision mediump float; #endif #define PI 3.14159265358979323846 uniform vec2 u_resolution; uniform float u_time; vec2 rotate2D (vec2 _st, float _angle) { _st -= 0.5; _st = mat2(cos(_angle),-sin(_angle), sin(_angle),cos(_angle)) * _st; _st += 0.5; return _st; } vec2 tile (vec2 _st, float _zoom) { _st *= _zoom; return fract(_st); } vec2 rotateTilePattern(vec2 _st){ // Scale the coordinate system by 2x2 _st *= 2.0; // Give each cell an index number // according to its position float index = 0.0; index += step(1., mod(_st.x,2.0)); index += step(1., mod(_st.y,2.0))*2.0; // | // 2 | 3 // | //-------------- // | // 0 | 1 // | // Make each cell between 0.0 - 1.0 _st = fract(_st); // Rotate each cell according to the index if(index == 1.0){ // Rotate cell 1 by 90 degrees _st = rotate2D(_st,PI*0.5); } else if(index == 2.0){ // Rotate cell 2 by -90 degrees _st = rotate2D(_st,PI*-0.5); } else if(index == 3.0){ // Rotate cell 3 by 180 degrees _st = rotate2D(_st,PI); } return _st; } void main (void) { vec2 st = gl_FragCoord.xy/u_resolution.xy; st = tile(st,3.0); st = rotateTilePattern(st); // Make more interesting combinations st = tile(st,2.0); st = rotate2D(st,-PI*u_time*0.25); st = rotateTilePattern(st*2.); st = rotate2D(st,PI*u_time*0.25); // step(st.x,st.y) just makes a b\u0026amp;w triangles // but you can use whatever design you want. gl_FragColor = vec4(vec3(step(st.x,st.y)),1.0); } fragment shader plasma #ifdef GL_ES precision mediump float; #endif uniform vec2 u_resolution; uniform vec2 u_mouse; uniform float u_time; float random (in vec2 st) { return fract(sin(dot(st.xy, vec2(12.9898,78.233)))* 43758.5453123); } vec2 random2(vec2 p) { return fract(sin(vec2(dot(p,vec2(127.1,311.7)),dot(p,vec2(269.5,183.3))))*43758.5453); } float cellular(vec2 p) { vec2 i_st = floor(p); vec2 f_st = fract(p); float m_dist = 10.; for (int j=-1; j\u0026lt;=1; j++ ) { for (int i=-1; i\u0026lt;=1; i++ ) { vec2 neighbor = vec2(float(i),float(j)); vec2 point = random2(i_st + neighbor); point = 0.5 + 0.5*sin(6.2831*point); vec2 diff = neighbor + point - f_st; float dist = length(diff); if( dist \u0026lt; m_dist ) { m_dist = dist; } } } return m_dist; } void main() { vec2 st = gl_FragCoord.xy / u_resolution.xy; st.x *= u_resolution.x / u_resolution.y; st *= 5.0; float r = cellular(st); float b = cellular(st - vec2(0.0, sin(u_time * 0.5) * 0.5)); gl_FragColor = vec4(r, 0.0, b, 1.0); } Aplicaciones\nEste tipo de texturas son utilizadas, debido a sus características, para el modelamiento de representaciones superficiales de elementos naturales, como lo podrían ser madera, mármol, piera, entre otros. Es por esto, que esta forma de representación podría ser utilizada en la ambientación de espacios, sobretodo en aquellos que, por sus mecánicas, pudieran requerir alto dinamismo y velocidad.\nConclusiones\nLas texturas procedimentales son una muestra de que existen mecanismos para el modelamiento de diferentes elementos de maneras altamente eficientes y efectivas. El uso de las texturas sobre sólidos permite emular elementos o estructuras para generar ambientación. Referencias\nhttps://en.wikipedia.org/wiki/Procedural_texture Shaders tomados de The Book of Shaders, https://thebookofshaders.com/09/ Fuente shader plasma: https://thebookofshaders.com/edit.php?log=161127235422 "},{"id":5,"href":"/showcase/docs/shortcodes/Shaders/Spatial_Coherence/","title":"Spatial Coherence","section":"Shaders","content":" Spatial Coherence # Marco teórico Se define a la coherencia espacial como un fenómeno, donde los objetos y los colores definidos en ellos varían según la distancia y posición del espectador, brindando al mismo un espectro de información más completo sobre su entorno, su profundidad y distribución.\nExercise\nImplement your own source dataset and a mechanism to select different images from it.\nSpatialCoherence.js \u0026#39;use strict\u0026#39;; let image_src; let video_src; let mosaic; // ui let resolution; let video_on; let mode; let photoSelect; let photoA; function preload() { // paintings are stored locally in the /sketches/shaders/paintings dir // and named sequentially as: p1.jpg, p2.jpg, ... p30.jpg // so we pick up one randomly just for fun: //image_src = loadImage(`/sketches/shaders/paintings/p${int(random(1, 3))}.jpg`); photoA = int(random(1, 6)); image_src = loadImage(`/showcase/sketches/photos/Photo${photoA}.jpg`); video_src = createVideo([\u0026#39;/showcase/sketches/mapache.webm\u0026#39;]); video_src.hide(); mosaic = readShader(\u0026#39;/showcase/sketches/SHADERS/Spacial_Coherence/SC.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.texcoords2 }); } function setup() { createCanvas(600, 600, WEBGL); textureMode(NORMAL); noStroke(); shader(mosaic); resolution = createSlider(1, 100, 30, 1); resolution.position(10, 35); resolution.style(\u0026#39;width\u0026#39;, \u0026#39;80px\u0026#39;); resolution.input(() =\u0026gt; mosaic.setUniform(\u0026#39;resolution\u0026#39;, resolution.value())); mosaic.setUniform(\u0026#39;resolution\u0026#39;, resolution.value()); video_on = createCheckbox(\u0026#39;video\u0026#39;, false); video_on.changed(() =\u0026gt; { if (video_on.checked()) { mosaic.setUniform(\u0026#39;source\u0026#39;, video_src); video_src.loop(); } else { mosaic.setUniform(\u0026#39;source\u0026#39;, image_src); video_src.pause(); } }); mosaic.setUniform(\u0026#39;source\u0026#39;, image_src); video_on.position(10, 55); mode = createSelect(); mode.position(10, 75); mode.option(\u0026#39;original\u0026#39;); mode.option(\u0026#39;pixelator\u0026#39;); mode.selected(\u0026#39;pixelator\u0026#39;); mode.changed(() =\u0026gt; { mosaic.setUniform(\u0026#39;original\u0026#39;, mode.value() === \u0026#39;original\u0026#39;); }); photoSelect = createSelect(); photoSelect.position(10, 95); photoSelect.option(\u0026#39;Photo1\u0026#39;); photoSelect.option(\u0026#39;Photo2\u0026#39;); photoSelect.option(\u0026#39;Photo3\u0026#39;); photoSelect.option(\u0026#39;Photo4\u0026#39;); photoSelect.option(\u0026#39;Photo5\u0026#39;); photoSelect.selected(`Photo${photoA}`) photoSelect.changed(() =\u0026gt; { if (photoSelect.value() == \u0026#39;Photo1\u0026#39;){ image_src = loadImage(`/showcase/sketches/photos/Photo1.jpg`); mosaic.setUniform(\u0026#39;source\u0026#39;, image_src); } if (photoSelect.value() == \u0026#39;Photo2\u0026#39;){ image_src = loadImage(`/showcase/sketches/photos/Photo2.jpg`); mosaic.setUniform(\u0026#39;source\u0026#39;, image_src); } if (photoSelect.value() == \u0026#39;Photo3\u0026#39;){ image_src = loadImage(`/showcase/sketches/photos/Photo3.jpg`); mosaic.setUniform(\u0026#39;source\u0026#39;, image_src); } if (photoSelect.value() == \u0026#39;Photo4\u0026#39;){ image_src = loadImage(`/showcase/sketches/photos/Photo4.jpg`); mosaic.setUniform(\u0026#39;source\u0026#39;, image_src); } if (photoSelect.value() == \u0026#39;Photo5\u0026#39;){ image_src = loadImage(`/showcase/sketches/photos/Photo5.jpg`); mosaic.setUniform(\u0026#39;source\u0026#39;, image_src); } }); } function draw() { // which previous exercise does this code actually solve? /* y v | | (-1,1)| (1,1) (0,1) (1,1) *_____|_____* *__________* | | | | | |_____|_____|__x | texture | | | | | space | *_____|_____* *__________*___ u (-1,-1) (1,-1) (0,0) (1,0) */ beginShape(); vertex(-1, -1, 0, 0, 1); vertex(1, -1, 0, 1, 1); vertex(1, 1, 0, 1, 0); vertex(-1, 1, 0, 0, 0); endShape(); } SpatialCoherence.frag precision mediump float; // source (image or video) is sent by the sketch uniform sampler2D source; // displays original uniform bool original; // target horizontal \u0026amp; vertical resolution uniform float resolution; // interpolated texcoord (same name and type as in vertex shader) // defined as a (normalized) vec2 in [0..1] varying vec2 texcoords2; void main() { if (original) { gl_FragColor = texture2D(source, texcoords2); } else { // define stepCoord to sample the texture source as a 3-step process: // i. define stepCoord as a texcoords2 remapping in [0.0, resolution] ∈ R vec2 stepCoord = texcoords2 * resolution; // ii. remap stepCoord in [0.0, resolution] ∈ Z // see: https://thebookofshaders.com/glossary/?search=floor stepCoord = floor(stepCoord); // iii. remap stepCoord in [0.0, 1.0] ∈ R stepCoord = stepCoord / vec2(resolution); // source texel gl_FragColor = texture2D(source, stepCoord); // ✨ source texels may be used to compute image palette lookup keys, // such as in video \u0026amp; photographic mosaics or ascii art visualizations. } } Aplicaciones\nEste tipo de fenómenos pueden aplicarse para generar un efecto ya sea de enfoque o desenfoque en elementos específicos, como de profundidad y ambientación de espacios.\nReferencias # https://visualcomputing.github.io/docs/shaders/spatial_coherence/ "},{"id":6,"href":"/showcase/docs/shortcodes/Shaders/Texturing/","title":"Texturing","section":"Shaders","content":" Ejercicios: Texturing # UV Visualization # Exercise\nRedefine the shape texture coordinates to turn the above image upside down.\nUV Visualization js let uvShader; function preload() { // Define geometry directly in clip space (i.e., matrices: Tree.NONE). // Interpolate only texture coordinates (i.e., varyings: Tree.texcoords2). // see: https://github.com/VisualComputing/p5.treegl#handling uvShader = readShader(\u0026#39;/showcase/sketches/SHADERS/UV_v/UV_inv.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.texcoords2 }); } function setup() { // shaders require WEBGL mode to work createCanvas(300, 300, WEBGL); noStroke(); // see: https://p5js.org/reference/#/p5/shader shader(uvShader); // https://p5js.org/reference/#/p5/textureMode // best and simplest is to just always used NORMAL textureMode(NORMAL); } function draw() { background(0); /* clip-space quad shape, i.e., both x and y vertex coordinates ∈ [-1..1] since textureMode is NORMAL, texture coordinates ∈ [-1..1] see: https://p5js.org/reference/#/p5/beginShape https://p5js.org/reference/#/p5/vertex y v | | (-1,1)| (1,1) (0,1) (1,1) *_____|_____* *__________* | | | | | |_____|_____|__x | texture | | | | | space | *_____|_____* *__________*___ u (-1,-1) (1,-1) (0,0) (1,0) */ beginShape(); vertex( 1, 1, 1, 1, 0); vertex( -1, 1, 0, 1, 0); vertex( -1, -1, 1, 1, 1); vertex(1, -1, -1, 0, 1); endShape(); // ✨ it\u0026#39;s worth noting (not mentioned in the p5 api docs though) // that quad (https://p5js.org/reference/#/p5/quad) also adds the // texture coords to each of its vertices. Hence: // quad(-1, -1, 1, -1, 1, 1, -1, 1); // produce the same results as the above beginShape / endShape } UV Visualization frag precision mediump float; // the texture coordinates varying was defined in // the vertex shader by treegl readShader() // open your console and \u0026amp; see! varying vec2 texcoords2; void main() { // glsl swizzling is both handy and elegant // see: https://www.khronos.org/opengl/wiki/Data_Type_(GLSL)#Swizzling gl_FragColor = vec4(texcoords2.xy, 0.0, 1.0); } Exercise\nInclude the blue channel in the uv visualization (e.g., use blue with red or green channels).\nUV 3D js let easycam; let uvShader; let opacity; let checkbox; let bc; function preload() { // Define geometry in world space (i.e., matrices: Tree.pmvMatrix). // The projection and modelview matrices may be emitted separately // (i.e., matrices: Tree.pMatrix | Tree.mvMatrix), which actually // leads to the same gl_Position result. // Interpolate only texture coordinates (i.e., varyings: Tree.texcoords2). // see: https://github.com/VisualComputing/p5.treegl#handling uvShader = readShader(\u0026#39;/showcase/sketches/SHADERS/UV_v/UV_3D.frag\u0026#39;, { matrices: Tree.pmvMatrix, varyings: Tree.texcoords2 }); } function setup() { createCanvas(300, 300, WEBGL); // easycam stuff let state = { distance: 250, // scalar center: [0, 0, 0], // vector rotation: [0, 0, 0, 1], // quaternion }; easycam = createEasyCam(); easycam.state_reset = state; // state to use on reset (double-click/tap) easycam.setState(state, 2000); // now animate to that state textureMode(NORMAL); opacity = createSlider(0, 1, 0.5, 0.01); opacity.position(10, 25); opacity.style(\u0026#39;width\u0026#39;, \u0026#39;280px\u0026#39;); checkbox = createCheckbox(\u0026#39;Blue Channel\u0026#39;, false); checkbox.style(\u0026#39;color\u0026#39;, \u0026#39;black\u0026#39;); checkbox.changed(myCheckedEvent); } function draw() { background(200); // reset shader so that the default shader is used to render the 3D scene resetShader(); // world space scene axes(); grid(); translate(0, -70); rotateY(0.5); fill(color(255, 0, 255, 125)); box(30, 50); translate(70, 70); fill(color(0, 255, 255, 125)); sphere(30, 50); // use custom shader shader(uvShader); // https://p5js.org/reference/#/p5.Shader/setUniform uvShader.setUniform(\u0026#39;opacity\u0026#39;, opacity.value()); uvShader.setUniform(\u0026#39;bc\u0026#39;, bc); // screen-space quad (i.e., x ∈ [0..width] and y ∈ [0..height]) // see: https://github.com/VisualComputing/p5.treegl#heads-up-display beginHUD(); noStroke(); quad(0, 0, width, 0, width, height, 0, height); endHUD(); } function mouseWheel(event) { //comment to enable page scrolling return false; } function myCheckedEvent() { if (checkbox.checked()) { bc = 1.0; console.log(\u0026#39;Blue!\u0026#39;); } else { bc = 0.0; console.log(\u0026#34;Not blue :(\u0026#34;); } } UV 3D js precision mediump float; varying vec2 texcoords2; varying vec4 color4; // uniform is sent by the sketch uniform float opacity; uniform float bc; void main() { gl_FragColor = vec4(texcoords2.xy, bc, opacity); } Texture Sampling # HSL( hue, saturation, lightness) y HSV ( hue, saturation, value o HSB con brightness) son formas alternativas de representar el modelo de color RGB.\nHue (Tono): Es el color mismo, definido físicamente por una longitud de onda. Saturation (Saturación): Es qué tan puro o intenso es ese matiz. Entre menos intenso fuera este tono, el resultado sería que el color percibido tendería al gris. Lightness (Luminosidad): Es la intensidad lumínica. Una gran intensidad es muy brillante y la percibimos como blanco y, si no hay intensidad o luz, se vuelve negro. Value (Valor): Representa la altura en el eje blanco-negro. Los valores posibles van del 0 al 100%. 0 siempre es negro. Luma: es el promedio ponderado de los valores RGB, basado en su contribución a la luminosidad percibida. Este se ha utilizado frecuentemente en la televisión. Component average: es el promedio de los valores RGB. texture sampling js let lumaShader; let img; let img2; let grey_scale; let hsv_scale; let brightnessO; let opcionS; let modo_tinte; let fotoS; const brightnessD = {\u0026#39;None\u0026#39;: 0, \u0026#39;Luma\u0026#39;:1, \u0026#39;HSV\u0026#39;:2, \u0026#39;HSL\u0026#39;:3, \u0026#39;Average\u0026#39;:4}; const opcionesS = {\u0026#39;None\u0026#39;: 0, \u0026#39;blend\u0026#39;:1, \u0026#39;add\u0026#39;:2,\u0026#39;darkest\u0026#39;:3,\u0026#39;lightest\u0026#39;:4, \u0026#39;difference\u0026#39;:5, \u0026#39;burn\u0026#39;:6}; function preload() { lumaShader = readShader(\u0026#39;/showcase/sketches/SHADERS/brightness_tinting/luma.frag\u0026#39;,{varyings: Tree.texcoords2 }); img = loadImage(\u0026#39;/showcase/sketches/perro_foto.jpg\u0026#39;); img2 = loadImage(\u0026#39;/showcase/sketches/pirotecniaA.jpg\u0026#39;); } function setup() { createCanvas(700, 500, WEBGL); noStroke(); textureMode(NORMAL); shader(lumaShader); brightnessO = createSelect(); brightnessO.position(15, 15); brightnessO.style(\u0026#39;width\u0026#39;, \u0026#39;90px\u0026#39;); brightnessO.option(\u0026#39;None\u0026#39;); brightnessO.option(\u0026#39;Luma\u0026#39;); brightnessO.option(\u0026#39;HSV\u0026#39;); brightnessO.option(\u0026#39;HSL\u0026#39;); brightnessO.option(\u0026#39;Average\u0026#39;); fotoS = createSelect(); fotoS.position(15, 45); fotoS.style(\u0026#39;width\u0026#39;, \u0026#39;90px\u0026#39;); fotoS.option(\u0026#39;perro\u0026#39;); fotoS.option(\u0026#39;pirotecnia\u0026#39;); colorPicker1 = createColorPicker(\u0026#39;blue\u0026#39;); colorPicker1.position(15,70); tinte = createCheckbox(\u0026#39;Tint\u0026#39;, false); tinte.style(\u0026#39;color\u0026#39;, \u0026#39;white\u0026#39;); tinte.position(15,105); modo = createSelect(); modo.position(15, 135); modo.style(\u0026#39;width\u0026#39;, \u0026#39;90px\u0026#39;); modo.option(\u0026#39;None\u0026#39;); modo.option(\u0026#39;blend\u0026#39;); modo.option(\u0026#39;add\u0026#39;); modo.option(\u0026#39;darkest\u0026#39;); modo.option(\u0026#39;ligthtest\u0026#39;); modo.option(\u0026#39;difference\u0026#39;); modo.option(\u0026#39;burn\u0026#39;); //modo.changed(modo_tinte_S); //lumaShader.setUniform(\u0026#39;texture\u0026#39;, img); } function draw() { background(255); color1=colorPicker1.color() if(fotoS.value()==\u0026#39;perro\u0026#39;){ lumaShader.setUniform(\u0026#39;texture\u0026#39;, img); } else if(fotoS.value()==\u0026#39;pirotecnia\u0026#39;){ lumaShader.setUniform(\u0026#39;texture\u0026#39;, img2); } lumaShader.setUniform(\u0026#39;brightnessO\u0026#39;, brightnessD[brightnessO.value()]); lumaShader.setUniform(\u0026#39;color_tinte\u0026#39;, color1.levels); lumaShader.setUniform(\u0026#39;tinte_a\u0026#39;, tinte.checked()); lumaShader.setUniform(\u0026#39;opcionS\u0026#39;, opcionesS[modo.value()]); quad(-width / 2, -height / 2, width / 2, -height / 2, width / 2, height / 2, -width / 2, height / 2); } texture sampling frag precision mediump float; // uniforms are defined and sent by the sketch uniform sampler2D texture; uniform int brightnessO; uniform int opcionS; uniform vec4 color_tinte; uniform bool tinte_a; // interpolated texcoord (same name and type as in vertex shader) varying vec2 texcoords2; // returns luma of given texel float luma(vec3 texel) { return 0.299 * texel.r + 0.587 * texel.g + 0.114 * texel.b; } float hsv(vec3 texel){ return max(max(texel.r, texel.g), texel.b); } float hsl(vec3 texel){ float maxColor = max(max(texel.r, texel.g), texel.b); float minColor = min(min(texel.r, texel.g), texel.b); return (maxColor + minColor)/2.0; } float average(vec3 texel) { return (texel.r + texel.g + texel.b)/3.0; } vec4 blend(vec4 texel){ return color_tinte * texel; } vec4 add(vec4 texel){ return color_tinte + texel; } vec4 difference(vec4 texel){ return max(texel, color_tinte) - min(texel, color_tinte); } vec4 lightest(vec4 texel){ return max(color_tinte, texel); } vec4 darkest(vec4 texel){ return min(color_tinte, texel); } vec4 burn(vec4 texel){ return max((1.0-((1.0-color_tinte)/texel)),0.0); } void main() { // texture2D(texture, texcoords2) samples texture at texcoords2 // and returns the normalized texel color vec4 texel = texture2D(texture, texcoords2); if (brightnessO == 0){ texel = texel; } else if (brightnessO == 1){ texel = vec4((vec3(luma(texel.rgb))), 1.0); } else if (brightnessO == 2){ texel = vec4((vec3(hsv(texel.rgb))), 1.0); } else if (brightnessO == 3){ texel = vec4((vec3(hsl(texel.rgb))), 1.0); } else if (brightnessO == 4){ texel = vec4((vec3(average(texel.rgb))), 1.0); } if (tinte_a){ if (opcionS == 1){ texel = blend(texel); } else if (opcionS == 2){ texel = add(texel); } else if (opcionS == 3) { texel = difference(texel); } else if (opcionS == 4){ texel = lightest(texel); } else if (opcionS == 5){ texel = darkest(texel); } else if (opcionS == 6){ texel = burn(texel); } } gl_FragColor = texel; } Conclusiones\nEl uso de diferentes herramientas de brillo y el tintado se pueden utilizar al tiempo para realizar diferentes cambios a una imagen. Utilizar, ademas de los anteriores, los distintos modos de mezcla de color permite que las imágenes generen o trasmitan diferentes sensaciones. Referencias # https://visualcomputing.github.io/docs/shaders/texturing/ https://github.com/jamieowen/glsl-blend "},{"id":7,"href":"/showcase/docs/shortcodes/Workshop_1/Ilusiones/","title":"Ilusiones","section":"Workshop 1","content":" Workshop #1: Ilusiones Ópticas # Introducción # Una ilusión óptica es una distorsión de la realidad que es percibida por el sentido de la vista. Este tipo de fenómeno ha permitido el estudio de cómo los seres humanos procesan la información. Adicionalmente, a lo largo de la historia se ha buscado recrear y experimentar con los sentidos de esta manera. Lo anterior, es el objetivo del siguiente informe, obteniendo una aproximación, no solo de cómo programar y experimentar con diferentes ilusiones, si no también entender el trasfondo científico que sustentan este comportamiento, consiguiendo la apropiada introducción a la computación visual.\nMarco teórico # A lo largo de la historia, se han descubierto muchos tipos de distorsiones que el cerebro humano genera con el fin de poder entender su entorno, como lo son las ilusiones auditivas y las ilusiones ópticas. Para el presente taller, se abordó el estudio de las ilusiones óptivas o visuales.\nUna ilusión, según la RAE, se refiere a:\nEl concepto, imagen o representación sin verdadera realidad, sugeridos por la imaginación o causados por engaño de los sentidos.\nEn el caso de las ilusiones ópticas, este engaño de los sentidos se da debido a los siguientes factores:\nOrganización perceptual: hace referencia a la forma en la que el cerebro organiza las sensaciones entrantes de información. Percepción de profundidad: se basa en cómo la mente intenta dar un sentido de profundidad a imágenes usualmente bidimensionales. Color y brillo: donde el humano, según la iluminación y la constancia del color, percibe la totalidad de un objeto. Objeto: se refiere a que, mientras los objetos conocidos tienen una forma o tamaño consistentes, independientemente de su perspectiva, los desconocidos pueden generar cambios inesperados según el punto de vista. Percepción futura: Se teoriza que una razón de las ilusiones ópticas son el retraso neuronal, causado por el tiempo en el que tarda en llegar la luz a la retina, esto siendo compensado por el cerebro generando imágenes de, lo que cree, puede ocurrir en milésimas de segundo en el futuro. -Artículo de Wikipedia\nAdicionalmente, se ha hecho una clasificación de las ilusiones visuales de esta manera:\nIlusiones ópticas fisiológicas: Se asocian a los efectos de una excesiva estimulación en los ojos, dadas por el color, el brillo y el movimiento. Ilusiones ópticas cognitivas: Se refieren a las relacionadas con una vulnerabilidad de la visión que exige al cerebro el entendimiento de algo que no considera claro. Ilusiones de ambiguedad: Son figuras que presentan dos alternativas de percepción no simultáneas. Ilusiones de distorsión: Se basan en los errores de percepción de un objeto o imagen. Ilusiones paradójicas: Presentan objetos imposibles. Ilusiones ficticias: Son aquellas que inducen al cerebro a la alucinación, debido a la inducción de alteraciones mentales. -Artículo de Blog XCARET\nMétodo # Como se explicó en el marco teórico, las ilusiones mostradas en este taller son ilusiones visuales, donde se perciben dichas ilusiones gracias al engaño a los sentidos. Asimismo, tenemos que la construcción de dichas ilusiones cognitivas (para este caso) dependen de dos factores:\nNo hay movimiento inducido Hay movimiento inducido En el caso de no hay movimiento inducido, se utilizan en todo momento dos funciones:\nPara crear el entorno la función setup(). function setup() { // Creación del canvas createCanvas(width, height) } Para la creación de los obtejos dentro del entorno canvas la función draw(). function draw() { // El píncel, aquí se dibujan líneas, establecen colores y se define la posición de los componentes ... ... } En este caso, únicamente se ubican componentes estáticos dentro del canvas. La ilusión es cognitiva pero todo el movimiento o dinamismo es generado por el \u0026ldquo;engaño \u0026quot; al cerebro inducido por el conjunto de componentes incluidos en la ilusión.\nEn el caso de hay movimiento inducido, se utilizan las mismas funciones y una más que sirve para interactuar con el usuario directamente.\nLa función mousePressed() se utiliza para definir en qué momentos el usuario puede hacer click en la pantalla y visualizará un cambio dinámico no generado por el cerebro, sino que será un cambio necesario para que se pueda notar el efecto de la ilusión. En el caso de la ilusión de los cuadrados rotando, se parte de utilizar la función draw() y una variable x dentro de un bucle for(){} para inducir movimiento a los cuadrados y hacerlos rotar en empezar a crecer a medida que avance el tiempo. Sin embargo, una variable a = true nos indica que el movimiento está activado, y es la función mousePressed() la encargada de llevarla a valor a = false y así ejecutar el siguiente código: function mousePressed() { if (a == false) { noLoop(); a = true; } else { loop(); a = false; } } Son entonces las funciones noLoop() y loop() las encargadas de parar y reanudar respectivamente, el movimiento inducido en la ilusión. Y es al parar la ilusión cuando se percibe el efecto de la ilusión.\nNOTA: La ilusión cuadrados rotando fue diseñada de forma accidental al realizar pruebas de construcción de componentes en el editor de p5. Más adelante se discuten las posibles causas de dicha ilusión.\nResultados # Ilusión lineas rectas # Únicamente con lineas rectas se consigue generar aparentes curvas. Se denomina curvas de Bézier a un sistema que se desarrolló hacia los años 1960 para el trazado de dibujos técnicos, en el diseño aeronáutico y en el de automóviles. Su denominación es en honor a Pierre Bézier, quien ideó un método de descripción matemática de las curvas que se comenzó a utilizar con éxito en los programas de CAD. Las curvas de Bézier han sido ampliamente usadas en los gráficos generados por ordenador para modelado de curvas suaves. -Articulo de Wikipedia p5-lines //{{\u0026lt; p5-iframe sketch=\u0026#34;/showcase/sketches/illusion_lines.js\u0026#34; width=\u0026#34;525\u0026#34; height=\u0026#34;525\u0026#34; \u0026gt;}} function setup() { createCanvas(500, 500); } function draw() { background(220); for(var i1=0;i1\u0026lt;500;){ line(0, i1, 10+i1, 500); i1+=10; } for(var i2=0;i2\u0026lt;500;){ line(500, 10+i2, i2, 0); i2+=10; } for(var i3=0;i3\u0026lt;500;){ line(0, 500-i3, 10+i3, 0); i3+=10; } for(var i4=0;i4\u0026lt;500;){ line(500-i4, 500, 500, i4); i4+=10; }\t} Ilusión de cuadricula # Ilusión psicológica en la cual se ven puntos en las intersecciones que aparecen y desaparecen. La ilusión de la cuadrícula de Hermann fue observada por Ludimar Hermann en 1870. Es muy similar a la anterior, cuando se mira un dibujo con una cuadrícula blanca sobre un fondo negro, se tiene la impresión de que surgen manchas \u0026ldquo;fantasmas\u0026rdquo; en las intersecciones de las líneas. Las manchas desaparecen cuando se observa directamente la intersección. Eso explica por qué se ven puntos en la intersección. -Articulo de Wikipedia\nAunque no hay una respuesta definitiva, se cree que ocurre por un proceso de inhibición neural lateral, en el que no interviene una sola célula o receptor en el campo visual, sino todo un conjunto de células que reaccionan ante los estímulos que se presentan. -Psicoactiva\np5-grid //{{\u0026lt; p5-iframe sketch=\u0026#34;/showcase/sketches/illusion_Grid.js\u0026#34; width=\u0026#34;445\u0026#34; height=\u0026#34;445\u0026#34; \u0026gt;}} function setup() { createCanvas(420, 420); } function draw() { background(\u0026#34;white\u0026#34;); for(var i=0; i \u0026lt; 400;) { for(var j=0; j\u0026lt;400; ){ rect(i, j, 20, 10); rect(i, j+20, 20, 10); j+=30 } fill(\u0026#34;black\u0026#34;); i+=30 } } Ilusión de paralelas # La ilusión de la pared de la cafetería es un tipo de ilusión óptico-geométrica, en la que líneas rectas paralelas, que dividen líneas entre filas formadas por baldosas blancas y negras alternas y escalonadas, aparentan estar inclinadas.\nLa ilusión fue atribuida en gran parte al fenómeno de la irradiación, y a la dispersión de la luz entre zonas oscuras y zonas brillantes en la imagen retinal.\nLa primera vez que se reporto esta ilusion fue en una pared de una cafetería, e incluso la fachada de un edificio en Melbourne utiliza esta ilusión. -Articulo de Wikipedia\np5-paralelas //{{\u0026lt; p5-iframe sketch=\u0026#34;/showcase/sketches/illusion_paralelas.js\u0026#34; width=\u0026#34;420\u0026#34; height=\u0026#34;425\u0026#34; \u0026gt;}} function setup() { createCanvas(400, 400); } function draw() { background(\u0026#34;white\u0026#34;); for (var i = 0; i \u0026lt; 400; i+=20) { line(0,20+i,400,20+i) } for (var j = 0; j \u0026lt; 50; j+=10) { for (var k = 0; k \u0026lt; 400; k+=50) { rect(0+(k+j/5), 20+j+j, 25, 20); rect(0+(k+10-j/5), 120+j+j, 25, 20); rect(0+(k+j/5), 220+j+j, 25, 20); rect(0+(k+10-j/5), 320+j+j, 25, 20); line(0,10,400,10) stroke(\u0026#34;gray\u0026#34;) fill(\u0026#34;black\u0026#34;) } } } El efecto desaparece cuando el blanco y el negro son reemplazados por colores diferentes, pero del mismo brillo. Ilusión cuadrado que \u0026ldquo;respira\u0026rdquo; # Ilusión óptica en la cual por la rotación y la visión limitada sobre el cuadrado pareciera que el tamaño de este mismo cambia. La falta de información del objeto completo hace que las imagenes rotando tengan un efecto de pulsaciones generado por la habilidad que tiene el cerebro de realizar interpolaciones de objetos en el espacio.\n-Breathing Square\np5-square //{{\u0026lt; p5-iframe sketch=\u0026#34;/showcase/sketches/breathing_square.js\u0026#34; width=\u0026#34;425\u0026#34; height=\u0026#34;425\u0026#34; \u0026gt;}} let angle = 0; function setup() { createCanvas(400, 400); angleMode(DEGREES); // stroke(\u0026#39;black\u0026#39;); noStroke(); } function draw() { background(252, 255, 216); push(); translate(200, 200); rotate(angle); fill(17, 0, 255); rectMode(CENTER); rect(0, 0, 200, 200); angle = angle + 3; pop(); if (!mouseIsPressed) { rectMode(CORNER); fill(255, 153, 55); rect(0, 0, 180, 180); rect(220, 0, 180, 180); rect(0, 220, 180, 180); rect(220, 220, 180, 180); } } Ilusión cuadrados rotando # En este caso, después de observar el punto en el centro de los cuadrados rotanto durante un tiempo, una vez pausado, se produce una sensación de movimiento en sentido contrario y mucho más lento. En este caso, se relacionó este efecto al fenomeno de afterimage, que si bien no es exactamente igual, puede tener similitudes en cómo funciona. Además, se pueden relacionar a ilusiones en las que se encuentran una gran cantidad de figuras geométricas iguales y tonalidades de color distintas, lo que hace que el cerebro reciba mucha información simultánea y de lugar a estos efectos. p5-squares //{{\u0026lt; p5-iframe sketch=\u0026#34;/showcase/sketches/squares_rotating.js\u0026#34; width=\u0026#34;625\u0026#34; height=\u0026#34;625\u0026#34; \u0026gt;}} function setup() { createCanvas(600, 600); // rectMode(CENTER); x_0 = 0; y_0 = 255; a = true; } function draw() { background(0); push(); translate(width / 2, height / 2); for (let x = 420; x \u0026gt;= 40; x = x / 1.08) { noStroke(); rotate(radians(frameCount / 2)); fill(y_0, 40); rect(0, 0, x, x); } pop(); point(300, 300); stroke(\u0026#34;blue\u0026#34;); strokeWeight(10); } function mousePressed() { if (a == false) { noLoop(); a = true; } else { loop(); a = false; } } Discusión # A partir de los resultados obtenidos, se discutieron los siguientes puntos:\nLas aplicaciones de las ilusiones ópticas:\nSegún lo visto en la sección marco teórico, se inició una discusión alrededor de las aplicaciones de las ilusiones ópticas. De ella y de la consulta de información al respecto, se obtuvo que las ilusiones ópticas funcionan como un recurso para el entendimiento del cerebro, a pesar de que varíen las conexiones neuronales entre persona y persona, hallando que no todas las personas perciben dichas ilusiones de la misma manera. - Presentación sobre ilusiones ópticas La creación de nuevas ilusiones ópticas:\nEl desarrollo del taller, junto con la experimentación y aprendizaje del lenguaje p5.js, permitió la creación de una ilusión visual que no se encontró durante la investigación del tema. Una vez encontrada la distorsión de la imagen, se comenzó una experimentación con la misma, lo cual permitió aprender de manera experimental la forma en la que los integrantes del grupo reaccionamos ante diferentes estímulos como lo son: la luz, el color, la forma y la velocidad de los elementos involucrados. Adicionalmente, se generó una consulta sobre ilusiones ópticas creadas recientemente, encontrando una gran cantidad de ilusiones y de concursos que se enfocan en esta área. - Concurso de ilusiones ópticas Conclusiones # Se puede concluir del presente informe, que la realización y entendimiento de las ilusiones ópticas, permite la experimentación con aspectos visuales como lo son la iluminación, el color, la sombra y el movimiento, los cuales son tópicos fundamentales en el estudio de todo lo relacionado a lo visual, en este caso a la programación enfocada a este campo. Finalmente, se pudo observar a lo largo del desarrollo del taller, las implicaciones a nivel mental y físico que las ilusiones ópticas generan, no solo a nivel experimental, sino desde el aspecto académico.\n"},{"id":8,"href":"/showcase/docs/shortcodes/Workshop_1/Masking/","title":"Masking","section":"Workshop 1","content":" Workshop #1: Masking # Introducción # El visual masking o enmascaramiento se puede entender como un paradigma, herramienta o fenómeno de percepción visual, el cual es utilizado para la cambiar la apariencia de una imagen mediante una máscara. Para el siguiente informe, teniendo como objetivo el entendimiento y profundización de este concepto como una base de la computación visual, se experimentó con los distintos componentes dados y se propusieron algoritmos que los implementen de forma eficiente.\nMarco teórico # Image Kernels # En procesamiento de imágenes un kernel, matriz de convolución o mask es una matriz utilizada para realizar ciertos cambio en una imagen. Esto, se consigue haciendo una convolución entre la imagen y el kernel.\nUna convolución es un proceso matemático, en el cual cada elemento de la imagen se suma con sus vecinos y se opera con la matriz. -Articulo de Wikipedia\nLa convolución puede ser aplicada a dos funciones cualesquiera de tiempo o espacio (u otras variables) para arrojar una tercera función: la salida de la convolución. -Energy Glossary\\ Lightness # La luminosidad, también llamada claridad, es una propiedad de los colores. Ella da una indicación sobre el aspecto luminoso del color estudiado: cuanto más oscuro es el color, la luminosidad es más débil. Sin embargo, se le puede dar más de una definición, una de las más simples, por ejemplo, es el promedio aritmético entre sus tres componentes en el modelo RGB. -Articulo de Wikipedia Para aumentar el brillo utilice la tecla \u0026ldquo;+\u0026rdquo;, para disminuirlo utilice la tecla \u0026ldquo;-\u0026rdquo; Image Histogram # Un histograma de imagen es un tipo de histograma que actúa como una representación gráfica de la distribución tonal de una imagen digital. El eje horizontal representa las variaciones tonales, mientras que el eje vertical representa el número total de pixeles en un tono en particular. En la parte izquierda del eje horizontal se encuentran las áreas más oscuras y en la parte derecha las más luminosas. Estos histogramas tienen diferentes aplicaciones en edición y procesamiento de imágenes. -Articulo de Wikipedia Método # Image Kernels # Para el desarrollo de esta parte del taller, se usaron 5 funciones:\nPara cargar la imagen seleccionada a procesar: preload() function preload() { img = loadImage('Images/images11.jpg'); } Para inicializar el canvas y los elementos del programa setup() function setup() { //Creation of the selection dropdown, to choose the kernel sel = createSelect(); //sel.position(10, 10); sel.option('Identity'); sel.option('Ridge detection'); sel.option('Sharpen'); sel.option('Blur'); sel.option('Convolution'); sel.option('Unsharp masking'); //Creation of canvas and a new empty image createCanvas(400, 200); pixelDensity(1); newimg = createImage(img.width, img.width); } Para crear y recorrer la imagen: draw() function draw() { //Gray empty canvas background(225); image(img, 0, 0); //Load original and new empy image newimg.loadPixels(); img.loadPixels(); if (sel.value() !== 'Identity') { //Establish the values of the wanted matrix matrix = selection(sel.value())[0]; //Establish the size of the kernel let sizem = selection(sel.value())[1]; //Loop through the image matrix for (var x = 0; x \u0026lt; newimg.width; x++) { for (var y = 0; y \u0026lt; newimg.height; y++) { //Get the colors resulting from the convolution let c = convolution(img, x, y, matrix, sizem); //Get the index from the matrix with pixelDensity = 1 var index = (y * newimg.width + x) * 4; //Set the new colors to the corresponding pixels newimg.pixels[index] = c[0]; newimg.pixels[index + 1] = c[1]; newimg.pixels[index + 2] = c[2]; newimg.pixels[index + 3] = 255; } } //Update de image newimg.updatePixels(); //Create a new image in the right half of the canvas image(newimg, width/2, 0); } else { //If the option is identity there's no need to loop the image image(img, width/2, 0); } } Vale la pena resaltar la fórmula para hallar el índice del pixel que se está evaluando:\nindex = (x + img.width * y)*4\nEsto, debido a que la matriz es la ventana de visualización x4, lo que implica que los primeros 4 índices, corresponderán a los valores R, G, B, A del píxel (0,0) (Esto asumiendo que la densidad del pixel será de 1), avanzando por pixel de 4 en 4.\nPara realizar la convolución: convolution(img, x, y, matrix, sizem) function convolution(img, x, y, matrix, sizem) { //Funcion that multiplies the current values with the kernel chosen //Declare de variables let r = 0.0; let g = 0.0; let b = 0.0; //Loop through the kernel for (var i = -1; i \u0026lt; sizem - 1; i++) { for (var j = -1; j \u0026lt; sizem - 1; j++) { let px = x + i; let py = y + j; //Calculate the index let index = (px + img.width * py)*4; //Make sure the index stays inside the range index = constrain(index, 0, img.pixels.length - 1); //Multiply the corresponding pixels with the kernel r += img.pixels[index] * matrix[i+1][j+1]; g += img.pixels[index + 1] * matrix[i+1][j+1]; b += img.pixels[index + 2] * matrix[i+1][j+1]; } } return [r,g,b]; } Para seleccionar un kernel: selection(value) function selection(value) { //Function that returns the chosen kernel and its size switch (value) { case 'Ridge detection': matrix = [ [ -1, -1, -1 ], [ -1, 8, -1 ], [ -1, -1, -1 ] ]; sizem = 3; break; case 'Sharpen': matrix = [ [ 0, -1, 0 ], [ -1, 5, -1 ], [ 0, -1, 0 ] ]; sizem = 3; break; case 'Blur': matrix = [ [ 1/9, 1/9, 1/9 ], [ 1/9, 1/9, 1/9 ], [ 1/9, 1/9, 1/9 ] ]; sizem = 3; break; case 'Convolution': matrix = [ [ -1, -1, -1 ], [ -1, 9, -1 ], [ -1, -1, -1 ] ]; sizem = 3; break; case 'Unsharp masking': matrix = [ [ -1/256, -4/256, -6/256, -4/256, -1/256 ], [ -4/256, -16/256, -24/256, -16/256, -4/256 ], [ -6/256, -24/256, 476/256, -24/256, -6/256], [ -4/256, -16/256, -24/256, -16/256, -4/256 ], [ -1/256, -4/256, -6/256, -4/256, -1/256 ]]; sizem = 5; break; default: matrix = [ [ -1, -1, -1 ], [ -1, 9, -1 ], [ -1, -1, -1 ] ]; sizem = 3; break; } return [matrix, sizem] } Lightness and Image Histogram # A partir del desarrollo de la sección anterior, se pudo lograr el segundo y tercer ítem. Se cambiaron y agregaron los siguientes componentes:\nPara crear y establecer el histograma de la imagen: draw() function draw() { var rango = 256; image(img, 0, 0); var histogram = new Array(rango); for (i = 0; i \u0026lt;= rango; i++) { histogram[i] = 0; } loadPixels(); for (var x = 0; x \u0026lt; img.width; x+=5) { for (var y = 0; y \u0026lt; img.height; y+=5) { var indice = (x + y * img.width) * 4; var a = pixels[indice]; var a2 = pixels[indice + 1]; var a3 = pixels[indice + 2]; var a4 = pixels[indice + 3]; b = int(a3); histogram[b]++; } } image(img, 0, 0); stroke(250,20,200); push(); translate(10,0) for (x = 0; x \u0026lt;= rango; x++) { index = histogram[x]; y1=int(map(index, 0, max(histogram), height, height-200)); y2 = height; xPos = map(x,0,rango,0, width-20); line(xPos, y1, xPos, y2); } pop(); } Para cambiar el brillo de la imagen: brillo(masomenos) function brillo(masomenos){ img.loadPixels(); for (var x = 0; x \u0026lt; img.width; x++) { for (var y = 0; y \u0026lt; img.height; y++) { var index = (y * img.width + x) * 4; if(masomenos){ img.pixels[index] = constrain(img.pixels[index]*1.1,0,255); img.pixels[index+1] = constrain(img.pixels[index+1]*1.1,0,255); img.pixels[index+2] = constrain(img.pixels[index+2]*1.1,0,255); } else{ img.pixels[index] = constrain(img.pixels[index]/1.1,0,255); img.pixels[index+1] = constrain(img.pixels[index+1]/1.1,0,255); img.pixels[index+2] = constrain(img.pixels[index+2]/1.1,0,255); } } } img.updatePixels(); image(img, width/2, 0); } Configurar el las teclas + y - para ajustar el brillo: keyPressed() function keyPressed() { switch (key) { case \u0026quot;+\u0026quot;: brillo(true); break; case \u0026quot;-\u0026quot;: brillo(false); break; } } Resultados # Aplicación con todos los casos anteriores juntos # p5-kernel image processing let img; let newimg; let d; let sel; function preload() { img = loadImage(\u0026#39;/showcase/sketches/perro_foto_dim.jpg\u0026#39;); } function setup() { //Creacion del menu para seleccionar kernel sel = createSelect(); sel.option(\u0026#39;Identity\u0026#39;); sel.option(\u0026#39;Ridge detection\u0026#39;); sel.option(\u0026#39;Sharpen\u0026#39;); sel.option(\u0026#39;Blur\u0026#39;); sel.option(\u0026#39;Convolution\u0026#39;); sel.option(\u0026#39;Unsharp masking\u0026#39;); createCanvas(500, 410); pixelDensity(1); newimg = createImage(img.width, img.width); } function draw() { background(225); image(img, 0, 0); let sizem = 3; newimg.loadPixels(); img.loadPixels(); /*xm = mouseX; ym = mouseY; */ if (sel.value() !== \u0026#39;Identity\u0026#39;) { matrix = selection(sel.value()); for (var x = 0; x \u0026lt; newimg.width; x++) { for (var y = 0; y \u0026lt; newimg.height; y++) { let c = convolution(img, x, y, matrix, sizem); var index = (y * newimg.width + x) * 4; newimg.pixels[index] = c[0]; newimg.pixels[index + 1] = c[1]; newimg.pixels[index + 2] = c[2]; newimg.pixels[index + 3] = 255; } } newimg.updatePixels(); image(newimg, width/2, 0); } else { image(img, width/2, 0); } var rango = 256 image(newimg, 0, 0); var histogram = new Array(rango); for (i = 0; i \u0026lt;= rango; i++) { histogram[i] = 0 } loadPixels(); for (var x1 = 0; x1 \u0026lt; newimg.width; x1+=5) { for (var y1 = 0; y1 \u0026lt; newimg.height; y1+=5) { var indice = (x1 + y1 * newimg.width) * 4; var a = pixels[indice]; var a2 = pixels[indice + 1]; var a3 = pixels[indice + 2]; var a4 = pixels[indice + 3]; b = int(a3); histogram[b]++ } } image(img, 0, 0); stroke(250,20,200) push() translate(10,0) for (x1 = 0; x1 \u0026lt;= rango; x1++) { index2 = histogram[x1]; y2=int(map(index2, 0, max(histogram), height, height-200)); y3 = height xPos = map(x1,0,rango,0, width-20) line(xPos, y2, xPos, y3); } pop() } function convolution(img, x, y, matrix, sizem) { let r = 0.0; let g = 0.0; let b = 0.0; for (var i = -1; i \u0026lt; sizem - 1; i++) { for (var j = -1; j \u0026lt; sizem - 1; j++) { let px = x + i; let py = y + j; let index = (px + img.width * py)*4; index = constrain(index, 0, img.pixels.length - 1); r += img.pixels[index] * matrix[i+1][j+1]; g += img.pixels[index + 1] * matrix[i+1][j+1]; b += img.pixels[index + 2] * matrix[i+1][j+1]; } } return [r,g,b]; } function selection(value) { switch (value) { case \u0026#39;Ridge detection\u0026#39;: matrix = [ [ -1, -1, -1 ], [ -1, 8, -1 ], [ -1, -1, -1 ] ]; break; case \u0026#39;Sharpen\u0026#39;: matrix = [ [ 0, -1, 0 ], [ -1, 5, -1 ], [ 0, -1, 0 ] ]; break; case \u0026#39;Blur\u0026#39;: matrix = [ [ 1/9, 1/9, 1/9 ], [ 1/9, 1/9, 1/9 ], [ 1/9, 1/9, 1/9 ] ]; break; case \u0026#39;Convolution\u0026#39;: matrix = [ [ -1, -1, -1 ], [ -1, 9, -1 ], [ -1, -1, -1 ] ]; break; case \u0026#39;Unsharp masking\u0026#39;: matrix = [ [ -1/256, -4/256, -6/256, -4/256, -1/256 ], [ -4/256, -16/256, -24/256, -16/256, -4/256 ], [ -6/256, -24/256, 476/256, -24/256, -6/256], [ -4/256, -16/256, -24/256, -16/256, -4/256 ], [ -1/256, -4/256, -6/256, -4/256, -1/256 ]]; sizem = 5; break; default: matrix = [ [ -1, -1, -1 ], [ -1, 9, -1 ], [ -1, -1, -1 ] ]; break; } return matrix } function brillo(masomenos){ newimg.loadPixels(); for (var x = 0; x \u0026lt; img.width; x++) { for (var y = 0; y \u0026lt; img.height; y++) { var index = (y * img.width + x) * 4; if(masomenos){ img.pixels[index] = constrain(img.pixels[index]*1.1,0,255); img.pixels[index+1] = constrain(img.pixels[index+1]*1.1,0,255); img.pixels[index+2] = constrain(img.pixels[index+2]*1.1,0,255); } else{ img.pixels[index] = constrain(img.pixels[index]/1.1,0,255); img.pixels[index+1] = constrain(img.pixels[index+1]/1.1,0,255); img.pixels[index+2] = constrain(img.pixels[index+2]/1.1,0,255); } } } img.updatePixels(); image(img, width/2, 0); } function keyPressed() { switch (key) { case \u0026#34;+\u0026#34;: brillo(true); break; case \u0026#34;-\u0026#34;: brillo(false); break; } } Discusión # Se discutió principalmente del uso del visual masking hoy en día, como una herramienta en la edición de fotografías y videos de formato digital, todo en base a cálculos matemáticos, visto en Image Kernels, y del uso que también se le puede dar para el análisis de la composición de las imágenes al aplicar una máscara y usar en conjunto otras herramientas como el Image Histogram.\nConclusiones # Se puede concluir que el uso del enmascaramiento como herramienta para la era digital es de gran utilidad ya que permite manipular y adaptar una imagen cuando es necesario para diferentes fines, como un “retoque” o un análisis que se le deba hacer, y durante el desarrollo del taller entendimos como esto es posible gracias a un código relativamente simple y corto que cualquiera con conocimientos básicos de programación podría entender.\n"},{"id":9,"href":"/showcase/docs/shortcodes/Workshop_2/Backroom/","title":"Backroom","section":"Workshop 2","content":" Workshop #2: 3d webgl application # Introducción # El modelamiento 3D es una herramienta que abre un mundo de posibilidades para representar el mundo real dentro del mundo digital. Inicialmente, los modelos en 2 dimensiones se utilizaban para diseñar todo tipo de invenciones, tales como: juegos, herramientas de desarrollo e incluso modelos de la vida real. Desde hace mucho tiempo, se utiliza el 2D y ha sido muy útil para los desarrolladores. Sin embargo, un mundo en 3 dimensiones es más semejante a la realidad, por lo que el modelamiento 3D desde hace ya varios años se ha convertido en una herramienta de representación de la realidad mucho más poderosa.\nPara modelar y representar cosas o aspectos de nuestro entorno utilizamos aplicaciones gráficas. Estas, tanto en 2D como en 3D, abren muchas posibilidades de diseño e interacción con el mundo digital. Por esto, WebGl busca acercar aún más (tanto a desarrolladores como a los apasionados por el modelamiento y la interacción gráfica) a utilizar recursos básicos en nuestro entorno digital como un navegador y una librería de Javascript, y así empezar a diseñar aplicaciones gráficas interactivas en la Web e incursionar en el mundo del modelamiento digital.\nMarco teórico # Para el desarrollo del presenta taller, es necesario entender los conceptos que los envuelven. El primero de ellos es WebGL, una especificación estándar que define una API implementada en JavaScript para la renderización de gráficos en 3D dentro de cualquier navegador web, el cual permite la combinación con todos los estándares web del navegador, permitiendo el procesamiento de canvas y la combinación con diferentes elementos de HTML. Es un motor de rasterización, el cual se ejecuta en la GPU de la computadora del desarrollador y que dibuja líneas, puntos y triángulos basados en el código suministrado. Adicionalmente, las instrucciones dadas son proporcionadas por WebGL en forma de pares de funciones, el sombreador de vértices y el sombreador de fragmentos, los cuales calculan las posiciones de vértices y calculan un color para cada píxel de lo primitivo que se está dibujando, respectivamente.\nUn componente fundamental de WebGL para el presente proyecto, es el de cámara, el cual utiliza propiedades matriciales y la aplicación de la matemática para visualización de imágenes según es requerido por el usuario. Las principales funcionalidades se encuentran en la rotación, movimiento e inversión de la visión del usuario, las cuales tienen múltiples aplicaciones en los campos de geografía y videojuegos, facilitando la inmersión en un campo de tres dimensiones.\nEl último de los conceptos importantes, es el de Backroom, siendo este la base del proyecto desarrollado. Los Backrooms es una leyenda urbana originada en un tablón de 4Chan en el año 2019, el cual inicialmente describe una habitación inquietante de origen y propósitos desconocidos. El impacto que generó la publicación permitió la extensión de este universo, que ahora describe un mundo alterno que se encuentra compuesto por una gran cantidad de niveles laberínticos y entidades que habitan allí, los cuales interactúan con las personas que accidentalmente caen allí.\nMétodo # Para el desarrollo de este taller se uso principalmete la biblioteca P5.js y sus funciones de objetos 3D, de estos se puede destacar el moviento de cámara, de personaje, creación de ambiente (columnas, paredes, suelo y techo) y colisiones.\nMovimiento de cámara # Para generar la sensación de movimiento en primera persona se desplaza la cámara utilizando las teclas, y se rota la dirección en la que apunta utilizando el movimiento del mouse. Para lograr esto, se utilizaron las funciones dispuestas en P5 para creación y manipulación de la cámara.\nfunction draw(){ background(0); noStroke(); cam.pan(ang(-D.cx)); cam.tilt(ang(D.cy)); D.r-=(mx*sensitivityX); yAng-=(my*sensitivityY); cam.setPosition(D.x,-D.y,D.z); Corrección de cámara # Para mantener la cámara dentro de la ventana cuando se deja de mover el mouse después de un movimiento suave devuelve sus variables D.x, D.y y D.z a 0.\nif(mx \u0026gt; 0){ mx--; } if(mx \u0026lt; 0){ mx++; } if(my \u0026gt; 0){ my--; } if(my \u0026lt; 0){ my++; } Al hacer un movimiento fuerte y prolongado de la cámara giraría sin control, pero se utilizó este limitador para que no suceda.\n//Evitar que la camara gire sin control if(mx\u0026gt;30 || mx \u0026lt;-30){ mx=0; } Movimiento de \u0026ldquo;personaje\u0026rdquo; # Para desplazar la cámara se desplazan las coordenadas de la cámara a una velocidad definida.\nD.cx=mx*sensitivityX; D.cy=my*sensitivityY; //Moviviento adelante if(keys[87] \u0026amp;\u0026amp; keyIsDown(16)){ playerSpeed=5; D.z-=cos(ang(D.r))*playerSpeed; D.x-=sin(ang(D.r))*playerSpeed; } if(keys[87]){ D.z-=cos(ang(D.r))*playerSpeed; D.x-=sin(ang(D.r))*playerSpeed; } //Moviviento atras if(keys[83]){ D.z+=cos(ang(D.r))*(playerSpeed-0.7); D.x+=sin(ang(D.r))*(playerSpeed-0.7); } //Moviviento izq if(keys[65]){ D.z-=cos(ang(D.r+90))*playerSpeed; D.x-=sin(ang(D.r+90))*playerSpeed; } //Moviviento derecha if(keys[68]){ D.z+=cos(ang(D.r+90))*playerSpeed; D.x+=sin(ang(D.r+90))*playerSpeed; } Creación de ambiente # Para facilitar la creación de niveles y mantener la escencia de un BACKROOM tradicional, la creación de varias estructuras es a traves de ciclos FOR, principalmente en las columnas, suelo y el techo.\nColumnas # Las columnas son una estructura para limitar las paredes y a nosotros los desarrolladores nos ayuda a ubicar puntos estrategicos en el nivel para su creación, y ayudar a crear un efecto que confunda al jugador haciendo que las habitasciones sean similares.\nDentro de la funcion draw() usamos un ciclo FOR anidado para crear las columnas del nivel, todas estan a la misma distacia una de la otra en el plano X y el plano Z.\nfor(var i = -2.5; i \u0026lt; 2.5; i++){ for(var j = -2.5; j \u0026lt; 2.5; j++){ push(); translate(i*500,1,j*500); rotateY(ang(90)); //fill(228,225,70); texture(walls); box(30,120,30); pop(); } } Paredes # Las paredes crean los pasillos y habitaciones del juego, se crean con la función pared() que definimos y crea un plano con la función plane() de P5. Además, le agregamos las coordenadas y modificación en los planos X, Y y Z.\nfunction pared(x,y,z,dx,dy,dz,l){ push(); translate(x,y,z); rotateX(ang(dx)); rotateY(ang(dy)); rotateZ(ang(dz)); texture(walls); fill(180,153,81); plane(l,110); pop(); Donde x, y \u0026amp; z son las coordenadas del punto de origen de la pared, dx, dy y dz son los ángulos de inclinación del plano y l es la longitud.\nTecho y suelo # Igual que las columnas se crean con un ciclo FOR y ayudan a limitar las habitaciones y pasillos en el juego.\n//Suelo for(var k = -20; k \u0026lt; 20; k++){ for(var l = -20; l \u0026lt; 20; l++){ push(); translate(k*100,50,l*100); rotateX(ang(90)); fill(100); texture(floor); plane(100); pop(); } } //Piso del piso push(); translate(0,100,0); rotateX(ang(90)); //fill(167, 164, 61); texture(floor); plane(10000); pop(); //Techo for(var k = -5; k \u0026lt; 5; k++){ for(var l = -5; l \u0026lt; 5; l++){ push(); translate(k*500,-90,l*500); rotateX(ang(90)); fill(100); texture(roof); plane(500); pop(); } } Texturas # Para añadir las texturas a los techos se utilizó la funcion de P5 texture() y las imágenes de las texturas.\nfunction preload() { roof = loadImage(\u0026#39;assets/images/techo.png\u0026#39;); walls = loadImage(\u0026#39;assets/images/walls.png\u0026#39;); floor = loadImage(\u0026#39;assets/images/floor.png\u0026#39;); } Colisiones # Al no tener una función definida para las colisiones limitaciones de movimiento al llegar a una pared con condicionales para que el jugador no pueda atravesarlas, es la creación de la habitación con sus coordenadas y mover al jugador a una posición atrás para dar la sensación de que no se puede avanzar más.\nif(D.z\u0026gt;=230){ D.z=229 } if(D.x\u0026gt;=230){ D.x=229 } if(D.z\u0026lt;=-1230){ D.z= -1229 } if(D.x\u0026lt;=-230 \u0026amp;\u0026amp; D.x\u0026gt;=-260 \u0026amp;\u0026amp; D.z\u0026gt;=-730 ){ D.x=-229 } if(D.x\u0026lt;-250 \u0026amp;\u0026amp; D.z\u0026gt;=-770 ){ D.z=-769; } if(D.x\u0026lt;-1230 ){ D.x=0; D.z=100; } Resultados # Aplicación completa. # La aplicación completa se puede visualizar en el siguiente link al repositorio donde está el código de la aplicación BACKROOM o clonando el repositorio y ejecutándolo de manera local.\nDiscusión # Teniendo como inspiración o idea fuente el concepto de las leyendas urbanas sobre los “Backrooms”, se discutió acerca de las características qué debe cumplir la aplicación para lograr transmitir un tipo de idea, en este caso, el del terror y suspenso causado por lo extraño del ambiente. Se consultaron fuentes referentes al tema del uso de la rotación y desplazamiento de la cámara y el uso de los colores y de las texturas en los objetos.\nTeniendo en cuenta lo mencionado anteriormente en el marco teórico, también se discutieron las aplicaciones del uso de la cámara en entornos digitales como videojuegos o distintas aplicaciones interactivas. De la misma manera, se conversó acerca de la importancia de aspectos como la disposición e interacciones de la cámara, junto a la ambientación, para simular situaciones o generar emociones en los usuarios y espectadores.\nConclusiones # Se puede concluir que el uso de la cámara, su rotación y desplazamiento, depende del propósito que se quiera lograr. En el caso del presente proyecto el uso de una cámara que se mantenga en primera persona dio mejores resultados para adaptarse al concepto original. Así como se puede considerar la cámara en tercera persona mejor para otros propósitos.\nAdemás, que la creación de una habitación y/o pasillo es en esencia el uso de traslación y rotaciones, que se adaptaron para crear este ambiente de Backroom, el uso de planos similares y repetitivos gracias a los ciclos FOR dan un toque tétrico que fue siempre el objetivo.\nSe pudo notar, adicionalmente, la importancia de librerías y aplicaciones preexistentes de diferentes funcionalidades, las cuales permiten un aprendizaje más eficiente de las diferentes posibilidades que tiene, en este caso, WebGL y P5.\n"},{"id":10,"href":"/showcase/Quienes_somos/Andres_Lopez/","title":"Andres Lopez","section":"¿Quiénes somos?","content":" Andrés Felipe López # Estudiante de Ingeniería de Sistemas y Computación\n"},{"id":11,"href":"/showcase/Quienes_somos/Juan_Callejas/","title":"Juan Callejas","section":"¿Quiénes somos?","content":" Juan Felipe Callejas # Estudiante de Ingeniería de Sistemas y Computación\n"},{"id":12,"href":"/showcase/Quienes_somos/Juliette_Lizarazo/","title":"Juliette Lizarazo","section":"¿Quiénes somos?","content":" Juliette Sofía Lizarazo # Estudiante de Ingeniería de Sistemas y Computación\n"},{"id":13,"href":"/showcase/Quienes_somos/Santiago_Sanchez/","title":"Santiago Sanchez","section":"¿Quiénes somos?","content":" Santiago Sánchez # Estudiante de Ingeniería de Sistemas y Computación\n"},{"id":14,"href":"/showcase/Quienes_somos/","title":"¿Quiénes somos?","section":"Introducción","content":" Integrantes # El grupo está conformado por\nAndres Lopez Andrés Felipe López # Estudiante de Ingeniería de Sistemas y Computación Juan Callejas Juan Felipe Callejas # Estudiante de Ingeniería de Sistemas y Computación Juliette Lizarazo Juliette Sofía Lizarazo # Estudiante de Ingeniería de Sistemas y Computación Santiago Sanchez Santiago Sánchez # Estudiante de Ingeniería de Sistemas y Computación "}]